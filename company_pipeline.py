import requests
from openai import OpenAI
from typing import List, Dict
from datetime import datetime
import re
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

class CompanyPipeline:
    def __init__(self, openai_key: str, alias_dict: Dict[str, str] = None):
        self.openai_key = openai_key
        self.alias_dict = alias_dict or {}
        self.client = OpenAI(api_key=self.openai_key)

    def resolve_alias(self, name: str) -> str:
        return self.alias_dict.get(name, name)

    def search_company_profile(self, query_name: str) -> str:
        url = "http://localhost:4000/search"
        params = {
            "q": f"{query_name} å…¬å¸ç°¡ä»‹ ç¶“ç‡Ÿé …ç›® ç”¢å“ ä¸Šä¸‹æ¸¸",
            "format": "json",
            "language": "zh",
            "sites": "zh.wikipedia.org ,104.com.tw, businessweekly.com.tw"
        }

        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            results = response.json().get("results", [])

            combined_text = ""
            for res in results:
                snippet = res.get("content") or res.get("title") or ""
                combined_text += snippet + "\n"
            return combined_text.strip()

        except Exception as e:
            print(f"âš ï¸ æŸ¥è©¢å…¬å¸ç°¡ä»‹å¤±æ•—ï¼š{e}")
            return ""

    def search_company_news(self, query_name: str, num_articles: int = 10) -> list:
        url = "http://localhost:4000/search"
        params = {
            "q": f"{query_name} ç›¸é—œæ–°è",
            "format": "json",
            "language": "zh",
            "categories": "news"
        }

        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            results = response.json()
            return [{
                "title": r.get("title", ""),
                "content": r.get("content", r.get("url", "")),
                "published": r.get("published", ""),
                "url": r.get("url", "")
            } for r in results.get("results", [])]
        except Exception as e:
            print(f"âš ï¸ æœ¬åœ° Perplexica æŸ¥è©¢éŒ¯èª¤ï¼š{e}")
            return []
        
    def summarize_profile_info(self, profile_text: str) -> Dict[str, List[str]]:
        """
        ä½¿ç”¨ OpenAI æ‘˜è¦å…¬å¸ç¶“ç‡Ÿé …ç›®ï¼Œèƒå–ç”¢å“ã€æŠ€è¡“èˆ‡ä¸Šä¸‹æ¸¸åˆä½œå°è±¡ã€‚
        """
        prompt = (
            "ä»¥ä¸‹æ˜¯æŸå…¬å¸åœ¨æ–°èèˆ‡ç¶²é ä¸Šçš„ç¶“ç‡Ÿé …ç›®èˆ‡ç”¢å“è³‡è¨Šæè¿°ï¼Œè«‹æ ¹æ“šå…§å®¹ç”¢å‡ºï¼š\n"
            "1. ä¸‰é …ä¸»è¦ç”¢å“\n"
            "2. å…©é …é—œéµæŠ€è¡“\n"
            "3. ä¸‰å€‹å¯èƒ½çš„ä¸Šä¸‹æ¸¸åˆä½œå°è±¡\n"
            "è«‹ä»¥åˆ—è¡¨æ–¹å¼åˆ—å‡ºï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚\n\n"
            f"{profile_text}"
        )

        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            result_text = response.choices[0].message.content.strip()

            # å˜—è©¦ä½¿ç”¨æ­£å‰‡è¡¨é”å¼ä¾†èƒå–é …ç›®
            result = {
                "ç”¢å“": re.findall(r"(?:ç”¢å“|ä¸€)[\s:ï¼š\-]*([^\n]+)", result_text),
                "æŠ€è¡“": re.findall(r"(?:æŠ€è¡“|äºŒ)[\s:ï¼š\-]*([^\n]+)", result_text),
                "ä¸Šä¸‹æ¸¸": re.findall(r"(?:åˆä½œå°è±¡|ä¸‰)[\s:ï¼š\-]*([^\n]+)", result_text),
            }

            return result
        except Exception as e:
            print(f"âš ï¸ OpenAI æ‘˜è¦å…¬å¸è³‡æ–™å¤±æ•—ï¼š{e}")
            return {"ç”¢å“": [], "æŠ€è¡“": [], "ä¸Šä¸‹æ¸¸": []}

    def summarize_with_openai(self, content: str) -> Dict[str, str]:
        prompt = f"ä»¥ä¸‹æ˜¯ä¸€ç¯‡é—œæ–¼æŸå®¶å…¬å¸çš„æ–°èï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡ç”¢å‡ºï¼š\n1. ä¸‰å¥è©±æ‘˜è¦ï¼›\n2. æ˜¯å¦å¯èƒ½å½±éŸ¿è©²å…¬å¸è‚¡åƒ¹ï¼ˆæ˜¯/å¦ + ç†ç”±ï¼‰ï¼š\n\n{content}"
        response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        summary = response.choices[0].message.content
        lines = summary.strip().split("\n")
        result = {"æ‘˜è¦": "", "é‡å¤§æ€§": ""}
        for line in lines:
            if "æ‘˜è¦" in line:
                result["æ‘˜è¦"] += line + "\n"
            elif "å½±éŸ¿" in line or "æ˜¯" in line or "å¦" in line:
                result["é‡å¤§æ€§"] = line
        return result
    
    def infer_supply_chain_role(self, summary_info: Dict[str, List[str]]) -> str:
        """
        æ ¹æ“šç”¢å“ã€æŠ€è¡“ã€ä¸Šä¸‹æ¸¸å°è±¡æ¨è«–ä¾›æ‡‰éˆè§’è‰²ã€‚
        """
        role_keywords = {
            "ä¸Šæ¸¸ï¼ˆICè¨­è¨ˆ/è£½é€ ï¼‰": ["IC", "æ™¶åœ“", "å°è£", "åŠå°é«”è£½ç¨‹", "ASIC", "æ™¶ç‰‡", "EDA", "å…‰ç½©","AI åŠ é€Ÿå¡"],
            "ä¸­æ¸¸ï¼ˆæ¨¡çµ„/çµ„è£ï¼‰": ["æ¨¡çµ„", "PCB", "æ•£ç†±", "å°è£æ¨¡çµ„", "æ§åˆ¶å™¨", "é›»æºç®¡ç†", "çµ„è£"],
            "ä¸‹æ¸¸ï¼ˆå“ç‰Œ/æ‡‰ç”¨ï¼‰": ["çµ‚ç«¯ç”¢å“", "å“ç‰Œ", "ç­†é›»", "æ‰‹æ©Ÿ", "è³‡æ–™ä¸­å¿ƒ", "è»Šç”¨", "ä¼ºæœå™¨"],
            "é€šè·¯æˆ–æ•´åˆå•†": ["ä»£ç†", "ç¶“éŠ·", "æ•´åˆ", "ODM", "OEM"]
        }

        combined_text = " ".join(summary_info.get("ç”¢å“", []) + summary_info.get("æŠ€è¡“", []) + summary_info.get("ä¸Šä¸‹æ¸¸", []))

        # é—œéµå­—ç°¡æ˜“åˆ¤æ–·
        role_scores = {role: sum(kw in combined_text for kw in kws) for role, kws in role_keywords.items()}
        sorted_roles = sorted(role_scores.items(), key=lambda x: x[1], reverse=True)

        if sorted_roles[0][1] == 0:
            # è‹¥ç„¡æ³•æ˜ç¢ºåˆ¤æ–·ï¼Œæ”¹ç”¨ LLM å¹«å¿™è£œæ¨è«–
            prompt = (
                "ä»¥ä¸‹æ˜¯æŸå®¶å…¬å¸æä¾›çš„ç”¢å“ã€æŠ€è¡“èˆ‡ä¸Šä¸‹æ¸¸åˆä½œå°è±¡è³‡è¨Šï¼Œ"
                "è«‹æ¨è«–è©²å…¬å¸åœ¨ä¾›æ‡‰éˆä¸­æœ€å¯èƒ½çš„è§’è‰²ï¼ˆä¸Šæ¸¸ã€ä¸­æ¸¸ã€ä¸‹æ¸¸ã€é€šè·¯/æ•´åˆå•†ï¼‰ï¼š\n\n"
                f"{combined_text}\n\n"
                "è«‹ç›´æ¥å›è¦†ä¸€ç¨®è§’è‰²ï¼Œä¸¦åŠ ä¸€å¥ç†ç”±ã€‚"
            )
            try:
                response = self.client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.2
                )
                return response.choices[0].message.content.strip()
            except Exception as e:
                print(f"âš ï¸ OpenAI åˆ¤æ–·ä¾›æ‡‰éˆè§’è‰²å¤±æ•—ï¼š{e}")
                return "æœªçŸ¥"
        else:
            # å›å‚³é—œéµå­—å‘½ä¸­æœ€é«˜è€…
            return f"{sorted_roles[0][0]}ï¼ˆä¾é—œéµè©æ¨è«–ï¼‰"

    def classify_industry(self, combined_text: str) -> str:
        from sentence_transformers import SentenceTransformer, util

        industry_keywords = {
            "AI ä¼ºæœå™¨": ["GPU", "AI åŠ é€Ÿå¡", "è³‡æ–™ä¸­å¿ƒ", "æ¶²å†·æ•£ç†±", "é‚Šç·£é‹ç®—","ASIC","æ™¶ç‰‡"],
            "é›»å‹•è»Š": ["é›»æ± ", "å……é›»æ¨", "é›»æ©Ÿ", "é›»é©…", "å‹•åŠ›æ¨¡çµ„"],
            "äººå½¢æ©Ÿå™¨äºº": ["ä¼ºæœå™¨é©…å‹•å™¨", "æ©Ÿå™¨è¦–è¦º", "äººæ©Ÿå”ä½œ", "SLAM", "AI é‹å‹•æ§åˆ¶"],
            "å…‰é›»ç”¢æ¥­": ["é¢æ¿", "å…‰å­¸", "æŠ•å½±", "å…‰å­¸é›·é”"],
            "å¤ªé™½èƒ½ç™¼é›»ç”¢æ¥­": ["å¤ªé™½èƒ½æ¨¡çµ„", "çŸ½æ™¶åœ“", "é€†è®Šå™¨"],
            "æ±½æ²¹è»Šç”¨é›¶çµ„ä»¶": ["ç¼¸é«”", "æ›²è»¸", "æ±½ç¼¸", "æ’æ°£ç®¡", "æ²¹å£“"],
            "ç‡Ÿå»ºæ¥­ã€å»ºå•†": ["ç‡Ÿå»ºå·¥ç¨‹", "å»ºæ¡ˆ", "å»ºç¯‰å¸«", "åœŸåœ°é–‹ç™¼"],
            "å·¥å…·æ©Ÿ": ["CNC", "åˆ‡å‰Š", "é‘½å­”", "åŠ å·¥ä¸­å¿ƒ", "è‡ªå‹•åŒ–æ©Ÿå°"],
            "åŠå°é«”": ["æ™¶åœ“", "IC", "è£½ç¨‹", "å…‰ç½©", "å°è£æ¸¬è©¦"],
            "è¢«å‹•å…ƒä»¶": ["é›»å®¹", "é›»é˜»", "é›»æ„Ÿ", "MLCC"],
            "é›»è…¦ç›¸é—œé›»å­é›¶çµ„ä»¶": ["ä¸»æ©Ÿæ¿", "æ•£ç†±æ¨¡çµ„", "æ»‘é¼ ", "éµç›¤", "SSD"],
            "æ‰‹æ©Ÿé›»å­é›¶çµ„ä»¶": ["è§¸æ§é¢æ¿", "è¢å¹•", "æŒ‡ç´‹è¾¨è­˜", "ç›¸æ©Ÿæ¨¡çµ„"]
        }

        model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        input_vec = model.encode(combined_text, convert_to_tensor=True)
        scores = {}
        for industry, keywords in industry_keywords.items():
            keywords_str = " ".join(keywords)
            kw_vec = model.encode(keywords_str, convert_to_tensor=True)
            sim = util.cos_sim(input_vec, kw_vec).item()
            scores[industry] = sim

        best_match = max(scores.items(), key=lambda x: x[1])
        return f"{best_match[0]}ï¼ˆç›¸ä¼¼åº¦ {best_match[1]:.4f}ï¼‰"

    def run(self, company_name: str) -> Dict:
        print(f"ğŸ§¾ åŸå§‹è¼¸å…¥åç¨±ï¼š{company_name}")
        query_name = self.resolve_alias(company_name)
        print(f"ğŸ” ä½¿ç”¨åˆ¥å/æŸ¥è©¢è©ï¼š{query_name}")

        # æŸ¥å…¬å¸ä»‹ç´¹æ–‡å­—ï¼ˆç¶“ç‡Ÿé …ç›® + ä¸Šä¸‹æ¸¸ï¼‰
        profile_text = self.search_company_profile(query_name)
        print(f"ğŸ“˜ å…¬å¸åŸºæœ¬è³‡æ–™æ“·å–é•·åº¦ï¼š{len(profile_text)}")

        # æŸ¥æ–°è
        news_list = self.search_company_news(query_name)
        all_news_text = "\n".join([n.get("content", "") for n in news_list])

        # åˆ†é¡ç”¢æ¥­ï¼ˆæ··åˆè³‡æ–™æºï¼‰
        all_content = profile_text + "\n" + "\n".join([n.get("content", "") for n in news_list])
        industry = self.classify_industry(all_content)

        profile_info = self.search_company_profile(query_name)
        profile_summary = self.summarize_profile_info(profile_info)
        role = self.infer_supply_chain_role(profile_summary)
        print(f"ğŸ“˜ é€éæœå°‹çš„å…¬å¸è³‡æ–™ä¾†å…¬å¸ç”¢æ¥­åœ°ä½æ¨è«–ï¼š{role}")
        
        
        # æ–°èæ‘˜è¦ + è©•åˆ†æ’åº
        summarized_news = []
        for n in news_list:
            title = n.get("title")
            content = n.get("content")
            date = n.get("published", "")
            url = n.get("url")
            if not content:
                continue
            result = self.summarize_with_openai(content)
            summarized_news.append({
                "æ¨™é¡Œ": title,
                "æ‘˜è¦": result["æ‘˜è¦"].strip(),
                "é‡å¤§æ€§": result["é‡å¤§æ€§"],
                "æ—¥æœŸ": date,
                "ä¾†æº": url,
                "å…¨æ–‡": content[:300] + "..."
            })

        # ä¾é‡å¤§æ€§æ’åºï¼ˆå…ˆåˆ—å‡ºæœ‰ã€Œæ˜¯ + ç†ç”±ã€çš„ï¼‰
        sorted_news = sorted(summarized_news, key=lambda x: ("æ˜¯" not in x["é‡å¤§æ€§"], x["æ—¥æœŸ"]), reverse=False)

        return {
            "å…¬å¸åç¨±": company_name,
            "å¯¦éš›æŸ¥è©¢åç¨±": query_name,
            "æ‰€å±¬ç”¢æ¥­åˆ†é¡": industry,
            "ä¾›æ‡‰éˆè§’è‰²": role,
            "ç¶“ç‡Ÿæ‘˜è¦": profile_summary,
            "é‡è¦æ–°èæ‘˜è¦åˆ—è¡¨": sorted_news
                }
